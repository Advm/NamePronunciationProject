{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from random import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ENG_FAM/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "languageFamily = {\n",
    "                \"Germanic\": '1000',\n",
    "                \"Romance\": '0100',\n",
    "                \"Sino-Tebetan\": '0010',\n",
    "                \"Japonic\": '0001'\n",
    "                }\n",
    "                \n",
    "languageTags = {\n",
    "            \"Germanic\": [cleanDatasets[0],cleanDatasets[1],cleanDatasets[2],cleanDatasets[3],cleanDatasets[4]],\n",
    "            \"Romance\": [cleanDatasets[5],cleanDatasets[6]],\n",
    "            \"Sino-Tebetan\":[cleanDatasets[7], cleanDatasets[8]],\n",
    "            \"Japonic\": [cleanDatasets[9]]\n",
    "            }\n",
    "\n",
    "\"\"\"Reads in all \"\"\"\n",
    "# Germanic Language Family\n",
    "df = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/english-general_american.csv\")\n",
    "df.name = \"English\"\n",
    "df2 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/english-received_pronunciation.csv\")\n",
    "df2.name = \"recevied\"\n",
    "df3 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/german.csv\")\n",
    "df3.name = \"german\"\n",
    "df4 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/swedish.csv\")\n",
    "df4.name = \"swed\"\n",
    "df5 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/norwegian-bokmal.csv\")\n",
    "df5.name = \"nor\"\n",
    "\n",
    "#Romance Language Family\n",
    "df7 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Romance/french-quebec.csv\")\n",
    "df7.name = \"quebec\"\n",
    "df8 = pd.read_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Romance/spanish-mexico.csv')\n",
    "df8.name = \"mexico\"\n",
    "\n",
    "\n",
    "#Sino-Tebetan Family\n",
    "#Cantonese is having an issue reading cantonese\n",
    "df10 = pd.read_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Sino-Tebetan/cantonese.csv')\n",
    "df10.name = \"cantonese\"\n",
    "\n",
    "#Mandarin has two spellings per word sometimes. Have to standardize data.\n",
    "df11 = pd.read_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Sino-Tebetan/mandarin.csv')\n",
    "df11.name = \"mandarin\"\n",
    "\n",
    "#Japonic\n",
    "df12 = pd.read_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/japanese.csv')\n",
    "df12.name = \"japonic\"\n",
    "\n",
    "ipaChars = pd.read_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/chars.csv')\n",
    "datasets = [df, df2, df3, df4, df5, df7, df8, df10, df11, df12]\n",
    "\n",
    "def removeIpaSlash(s):\n",
    "  \"\"\"Function to remove slashses from the IPA Pronunciation\"\"\"\n",
    "  return s.replace(\"/\", \"\")\n",
    "\n",
    "cleanDatasets = []\n",
    "for d in datasets:\n",
    "    d['Pronunciations'] = d['Pronunciations'].map(removeIpaSlash)\n",
    "    cleanDatasets.append(d.sample(frac=1).reset_index(drop=True))\n",
    "    cleanDatasets[len(cleanDatasets) - 1].name = d.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "recevied\n",
      "german\n",
      "swed\n",
      "nor\n",
      "167068\n"
     ]
    }
   ],
   "source": [
    "temparr = []\n",
    "for dataset in languageTags[\"Germanic\"]:\n",
    "    sampleSetPopulation = len(dataset)//3\n",
    "    print(dataset.name)\n",
    "    for i in range(sampleSetPopulation):\n",
    "        temp = []\n",
    "        # print(\"On Iteration: \" + str(i) + \" of \" + str(sampleSetPopulation))\n",
    "        for j in ipaChars['Char']:\n",
    "            if j in dataset['Pronunciations'][i]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        for k in languageFamily[\"Germanic\"]:\n",
    "            temp.append(int(k))\n",
    "        temparr.append(temp)\n",
    "\n",
    "print(len(temparr))\n",
    "bigdataset = pd.DataFrame(temparr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quebec\n",
      "mexico\n",
      "280614\n"
     ]
    }
   ],
   "source": [
    "temparr2 = []\n",
    "for dataset in languageTags[\"Romance\"]:\n",
    "    sampleSetPopulation = len(dataset)//3\n",
    "    print(dataset.name)\n",
    "    for i in range(sampleSetPopulation):\n",
    "        # print(\"On Iteration: \" + str(i) + \" of \" + str(sampleSetPopulation))\n",
    "        temp = []\n",
    "        for j in ipaChars['Char']:\n",
    "            if j in dataset['Pronunciations'][i]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        for k in languageFamily[\"Romance\"]:\n",
    "            temp.append(int(k))\n",
    "        temparr2.append(temp)\n",
    "\n",
    "print(len(temparr2))\n",
    "bigdataset2 = pd.DataFrame(temparr2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cantonese\n",
      "mandarin\n",
      "We Are out of the loop\n",
      "33868\n",
      "       0    1    2    3    4    5    6    7    8    9    ...  204  205  206  \\\n",
      "0        0    0    0    0    0    0    1    1    0    0  ...    0    0    0   \n",
      "1        0    0    0    0    0    0    1    0    0    0  ...    0    0    0   \n",
      "2        0    0    0    0    1    0    1    0    0    0  ...    0    0    0   \n",
      "3        1    0    0    1    1    0    1    0    0    0  ...    0    0    0   \n",
      "4        0    0    0    0    0    1    1    0    0    0  ...    0    0    0   \n",
      "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
      "33863    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "33864    0    0    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
      "33865    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "33866    0    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
      "33867    1    0    0    0    1    0    0    1    0    0  ...    0    0    0   \n",
      "\n",
      "       207  208  209  210  211  212  213  \n",
      "0        0    0    0    0    0    1    0  \n",
      "1        0    0    0    0    0    1    0  \n",
      "2        0    0    0    0    0    1    0  \n",
      "3        0    0    0    0    0    1    0  \n",
      "4        0    0    0    0    0    1    0  \n",
      "...    ...  ...  ...  ...  ...  ...  ...  \n",
      "33863    0    0    0    0    0    1    0  \n",
      "33864    0    0    0    0    0    1    0  \n",
      "33865    0    0    0    0    0    1    0  \n",
      "33866    0    0    0    0    0    1    0  \n",
      "33867    0    0    0    0    0    1    0  \n",
      "\n",
      "[33868 rows x 214 columns]\n"
     ]
    }
   ],
   "source": [
    "temparr3 = []\n",
    "for dataset in languageTags[\"Sino-Tebetan\"]:\n",
    "    sampleSetPopulation = len(dataset)//3\n",
    "    print(dataset.name)\n",
    "    for i in range(sampleSetPopulation):\n",
    "        # print(\"On Iteration: \" + str(i) + \" of \" + str(sampleSetPopulation))\n",
    "        temp = []\n",
    "        for j in ipaChars['Char']:\n",
    "            if j in dataset['Pronunciations'][i]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        for k in languageFamily[\"Sino-Tebetan\"]:\n",
    "            temp.append(int(k))\n",
    "        temparr3.append(temp)\n",
    "\n",
    "print(len(temparr3))\n",
    "bigdataset3 = pd.DataFrame(temparr3)\n",
    "print(bigdataset3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "japonic\n",
      "167068\n"
     ]
    }
   ],
   "source": [
    "temparr4 = []\n",
    "for dataset in languageTags[\"Japonic\"]:\n",
    "    sampleSetPopulation = len(dataset)//3\n",
    "    print(dataset.name)\n",
    "    for i in range(sampleSetPopulation):\n",
    "        # print(\"On Iteration: \" + str(i) + \" of \" + str(sampleSetPopulation))\n",
    "        temp = []\n",
    "        for j in ipaChars['Char']:\n",
    "            if j in dataset['Pronunciations'][i]:\n",
    "                temp.append(1)\n",
    "            else:\n",
    "                temp.append(0)\n",
    "        for k in languageFamily[\"Japonic\"]:\n",
    "            temp.append(int(k))\n",
    "        temparr4.append(temp)\n",
    "\n",
    "print(len(temparr))\n",
    "bigdataset4 = pd.DataFrame(temparr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffledDatasets = [bigdataset, bigdataset2, bigdataset3, bigdataset4]\n",
    "concatenatedDatasets = pd.concat(shuffledDatasets, ignore_index=True)\n",
    "# shuffledDatasets = [bigdataset, bigdataset2]\n",
    "# concatenatedDatasets = pd.concat(shuffledDatasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>204</th>\n",
       "      <th>205</th>\n",
       "      <th>206</th>\n",
       "      <th>207</th>\n",
       "      <th>208</th>\n",
       "      <th>209</th>\n",
       "      <th>210</th>\n",
       "      <th>211</th>\n",
       "      <th>212</th>\n",
       "      <th>213</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555028</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555029</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555030</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555031</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555032</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>555033 rows × 214 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9    ...  204  205  206  \\\n",
       "0         0    1    0    0    1    0    0    0    0    0  ...    0    0    0   \n",
       "1         0    1    0    0    0    0    0    0    0    1  ...    0    0    0   \n",
       "2         0    1    0    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "3         0    1    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "4         0    1    0    0    0    1    1    1    0    1  ...    0    0    0   \n",
       "...     ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "555028    1    0    0    0    0    0    0    0    0    0  ...    0    0    0   \n",
       "555029    1    0    1    0    0    1    0    0    0    0  ...    0    0    0   \n",
       "555030    0    0    0    0    0    1    1    0    0    0  ...    0    0    0   \n",
       "555031    1    0    0    0    0    1    1    0    0    0  ...    0    0    0   \n",
       "555032    1    0    1    1    0    1    0    1    0    0  ...    0    0    0   \n",
       "\n",
       "        207  208  209  210  211  212  213  \n",
       "0         0    0    0    1    0    0    0  \n",
       "1         0    0    0    1    0    0    0  \n",
       "2         0    0    0    1    0    0    0  \n",
       "3         0    0    0    1    0    0    0  \n",
       "4         0    0    0    1    0    0    0  \n",
       "...     ...  ...  ...  ...  ...  ...  ...  \n",
       "555028    0    0    0    0    0    0    1  \n",
       "555029    0    0    0    0    0    0    1  \n",
       "555030    0    0    0    0    0    0    1  \n",
       "555031    0    0    0    0    0    0    1  \n",
       "555032    0    0    0    0    0    0    1  \n",
       "\n",
       "[555033 rows x 214 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenatedDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store concatenatedDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalDataset = concatenatedDatasets.sample(frac=1).reset_index(drop=True)\n",
    "finalDataset.to_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/finaldataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential()\n",
    "network.add(keras.Input(shape=(210,)))\n",
    "network.add(Dense(150, activation='relu'))\n",
    "network.add(Dense(100, activation='relu'))\n",
    "network.add(Dense(100, activation='relu'))\n",
    "network.add(Dense(len(languageFamily), activation='sigmoid'))\n",
    "network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # # print(len(resultXTrain))\n",
    "# # # print(len(resultYTrain))\n",
    "# # # print(len(resultXTest))\n",
    "# # # print(len(resultYTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetLength = len(finalDataset)\n",
    "index = round(datasetLength * .05)\n",
    "print(index)\n",
    "\n",
    "\n",
    "N = 4\n",
    "# Select last 4 columns of dataframe\n",
    "xValues = finalDataset.iloc[:, 0:-N]\n",
    "yValues = finalDataset.iloc[: , -N:]\n",
    "\n",
    "resultXTrain = pd.DataFrame(xValues[:index])\n",
    "resultXTrain.columns = ipaChars['Char'].values \n",
    "\n",
    "resultXTest = pd.DataFrame(xValues[index:])\n",
    "resultXTest.columns = ipaChars['Char'].values \n",
    "\n",
    "resultYTrain = pd.DataFrame(yValues[:index])\n",
    "resultYTest = pd.DataFrame(yValues[index:])\n",
    "# print(resultXTrain)\n",
    "# print(resultXTest)\n",
    "\n",
    "# %store resultXTrain\n",
    "# %store resultYTrain\n",
    "# %store resultXTest\n",
    "# %store resultYTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "finalDataset\n",
    "temp[\"Out1\"] = finalDataset[210]\n",
    "temp[\"Out2\"] = finalDataset[211]\n",
    "temp[\"Out3\"] = finalDataset[212]\n",
    "temp[\"Out4\"] = finalDataset[213]\n",
    "X_train = finalDataset.drop([210, 211, 212, 213], axis=1)[:index]\n",
    "y_train = temp[:index]\n",
    "X_test = finalDataset.drop([210, 211, 212, 213], axis=1)[index:]\n",
    "y_test = temp[index:]\n",
    "temp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.autograph.experimental.do_not_convert(network.fit(X_train, y_train, epochs=40, validation_data=(X_test, y_test), verbose=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.save(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = []\n",
    "# for j in ipaChars['Char']:\n",
    "#     if j in \"ˈfɹoʊmɪŋ\":\n",
    "#         temp.append(1)\n",
    "#     else:\n",
    "#         temp.append(0)\n",
    "\n",
    "# pDF = pd.DataFrame([temp])\n",
    "# pDF.columns = ipaChars['Char'].values\n",
    "# pDF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.autograph.experimental.do_not_convert(network.predict(pDF))\n",
    "# network(pDF, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(network.weights)\n",
    "# print(pDF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00aa7deaa002eace83cde9fdbccd45f22b0b2c9563d542b6baf8a183e1387b2a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

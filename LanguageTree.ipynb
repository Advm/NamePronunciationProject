{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from random import shuffle\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from googletrans import Translator\n",
    "from unidecode import unidecode\n",
    "from sklearn.model_selection import train_test_split\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/ENG_FAM/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3441: DtypeWarning: Columns (2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "translator = Translator()\n",
    "\n",
    "#Longest Word in English Language\n",
    "maxLetters = 25\n",
    "\n",
    "languageFamily = {\n",
    "                \"Germanic\": '1000',\n",
    "                \"Romance\": '0100',\n",
    "                \"Sino-Tebetan\": '0010',\n",
    "                \"Japonic\": '0001'\n",
    "                }\n",
    "\"\"\"Reads in all \"\"\"\n",
    "# Germanic Language Family\n",
    "df = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/english-general_american.csv\")\n",
    "df.name = \"English\"\n",
    "df2 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/english-received_pronunciation.csv\")\n",
    "df2.name = \"recevied\"\n",
    "df3 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/german.csv\")\n",
    "df3.name = \"german\"\n",
    "df4 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/swedish.csv\")\n",
    "df4.name = \"swed\"\n",
    "df5 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Germanic/norwegian-bokmal.csv\")\n",
    "df5.name = \"nor\"\n",
    "\n",
    "#Romance Language Family\n",
    "df7 = pd.read_csv(\"/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Romance/french-quebec.csv\")\n",
    "df7.name = \"quebec\"\n",
    "df8 = pd.read_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Romance/spanish-mexico.csv')\n",
    "df8.name = \"mexico\"\n",
    "\n",
    "\n",
    "#Sino-Tebetan Family\n",
    "\n",
    "#Cantonese is having an issue reading cantonese\n",
    "df10 = pd.read_csv('/Users/adamvalencia/Git/NamePronunciationProject/ipa_dicts/Sino-Tebetan/cantonese.csv')\n",
    "df10.name = \"cantonese\"\n",
    "\n",
    "#Mandarin has two spellings per word sometimes. Have to standardize data.\n",
    "df11 = pd.read_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/Sino-Tebetan/mandarin.csv')\n",
    "df11.name = \"mandarin\"\n",
    "\n",
    "#Japonic\n",
    "df12 = pd.read_csv('/Users/vincent/Git/PronunciationProject/NamePronunciationProject/ipa_dicts/japanese.csv')\n",
    "df12.name = \"japonic\"\n",
    "\n",
    "datasets = [df, df2, df3, df4, df5, df7, df8, df10, df11, df12]\n",
    "\n",
    "def removeIpaSlash(s):\n",
    "  \"\"\"Function to remove slashses from the IPA Pronunciation\"\"\"\n",
    "  return s.replace(\"/\", \"\")\n",
    "\n",
    "cleanDatasets = []\n",
    "for d in datasets:\n",
    "    d['Pronunciations'] = d['Pronunciations'].map(removeIpaSlash)\n",
    "    cleanDatasets.append(d.sample(frac=1).reset_index(drop=True))\n",
    "    cleanDatasets[len(cleanDatasets) - 1].name = d.name\n",
    "\n",
    "languageTags = {\n",
    "            \"Germanic\": [cleanDatasets[0],cleanDatasets[1],cleanDatasets[2],cleanDatasets[3],cleanDatasets[4]],\n",
    "            \"Romance\": [cleanDatasets[5],cleanDatasets[6]],\n",
    "            \"Sino-Tebetan\":[cleanDatasets[7], cleanDatasets[8]],\n",
    "            \"Japonic\": [cleanDatasets[9]]\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def processWord(word, tag):\n",
    "#     \"\"\"Process a string that removes punctuation and is not longer than 15 letters.\"\"\"\n",
    "#     uniEncoded = []\n",
    "#     print(\"Orginal is: \" + word)\n",
    "#     if tag == \"Sino-Tebetan\":\n",
    "#         lower = translator.translate(word, dest='en', src='zh-cn').text.lower()\n",
    "#     elif tag == \"Japonic\":\n",
    "#         lower = translator.translate(word, dest='en',  src='ja').text.lower()\n",
    "#     else:\n",
    "#         lower = word.lower()\n",
    "    \n",
    "#     finalString = re.sub(r'[^A-Za-zÀ-ÖØ-öø-ÿ]', '', lower)\n",
    "#     print(\"translated word is: \" + finalString)\n",
    "#     if len(finalString) <= maxLetters:\n",
    "#         # uniEncoded.append(finalString)\n",
    "#         return finalString\n",
    "\n",
    "#     return ''\n",
    "\n",
    "# def unicodeConverter(char):\n",
    "#     \"\"\"Returns the array ascii representation for a word\n",
    "#     There are 52 total lettesr in ASCII\"\"\"\n",
    "#     uniValue = ord(char)\n",
    "\n",
    "#     #Ranges for ASCII Represneation of word\n",
    "#     if uniValue in range(ord('A'), ord('Z') + 1):\n",
    "#         return uniValue - ord('A')\n",
    "#     elif uniValue in range(ord('a'),ord('z') + 1):\n",
    "#         return uniValue - ord('a')\n",
    "#     elif uniValue in range(ord('À'),ord('Ö') + 1):\n",
    "#         return uniValue - ord('À')\n",
    "#     elif uniValue in range(ord('Ø'),ord('ö') + 1):\n",
    "#         return uniValue - ord('Ø')\n",
    "#     elif uniValue in range(ord('ø'),ord('ÿ') + 1):\n",
    "#         return uniValue - ord('ø')\n",
    "#     elif uniValue in range(ord('Ø'),ord('ö') + 1):\n",
    "#         return uniValue - ord('Ø')\n",
    "#     else:\n",
    "#         print(\"Unrecognized Character \" + char)\n",
    "#         exit(1)\n",
    "\n",
    "def convertDictionaryToVector(word):\n",
    "    \"\"\"Given a word convert the string to their binary\n",
    "    vector counterpart.\"\"\"\n",
    "\n",
    "    vector = \"\"\n",
    "    for letter in word:\n",
    "        ind = unicodeConverter(letter)\n",
    "        vector += (str(0)*ind) + str(1) + str(0)*(51-ind)\n",
    "    if len(word) <= maxLetters:\n",
    "        vector += str(0)*52*(maxLetters - len(word))\n",
    "    else:\n",
    "        vector = \"\"\n",
    "    \n",
    "    return vector\n",
    "\n",
    "def createOutputVector(tagIdx, numLanguages):\n",
    "    return str(0)*tagIdx + str(1) + str(0)*(numLanguages - 1 - tagIdx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Pronunciations</th>\n",
       "      <th>AltPronunciations1</th>\n",
       "      <th>AltPronunciations2</th>\n",
       "      <th>AltPronunciations3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>täuschest</td>\n",
       "      <td>ˈtɔøʃɛst</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Münzen</td>\n",
       "      <td>ˈmʏnt͡sn̩</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>zusammenbrechendes</td>\n",
       "      <td>ˈtsuːˌzammɛnbrɛçɛndəs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Püppchens</td>\n",
       "      <td>ˈpʏppçɛns</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dezentere</td>\n",
       "      <td>deˈtsɛntɐ̯ə</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278909</th>\n",
       "      <td>gottgegebenem</td>\n",
       "      <td>ˈgɔttgegebənəm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278910</th>\n",
       "      <td>pendelndes</td>\n",
       "      <td>ˈpɛndɛlndəs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278911</th>\n",
       "      <td>schärferem</td>\n",
       "      <td>ˈʃɛɾfɐ̯əm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278912</th>\n",
       "      <td>anzurechnend</td>\n",
       "      <td>ʔanˈtsuːˌɾɛçnɛnt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278913</th>\n",
       "      <td>unehrlich</td>\n",
       "      <td>ˈʔʊnˌʔeɾlɪç</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278914 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Word         Pronunciations  AltPronunciations1  \\\n",
       "0                täuschest               ˈtɔøʃɛst                 NaN   \n",
       "1                   Münzen              ˈmʏnt͡sn̩                 NaN   \n",
       "2       zusammenbrechendes  ˈtsuːˌzammɛnbrɛçɛndəs                 NaN   \n",
       "3                Püppchens              ˈpʏppçɛns                 NaN   \n",
       "4                dezentere            deˈtsɛntɐ̯ə                 NaN   \n",
       "...                    ...                    ...                 ...   \n",
       "278909       gottgegebenem         ˈgɔttgegebənəm                 NaN   \n",
       "278910          pendelndes            ˈpɛndɛlndəs                 NaN   \n",
       "278911          schärferem              ˈʃɛɾfɐ̯əm                 NaN   \n",
       "278912        anzurechnend       ʔanˈtsuːˌɾɛçnɛnt                 NaN   \n",
       "278913           unehrlich            ˈʔʊnˌʔeɾlɪç                 NaN   \n",
       "\n",
       "        AltPronunciations2  AltPronunciations3  \n",
       "0                      NaN                 NaN  \n",
       "1                      NaN                 NaN  \n",
       "2                      NaN                 NaN  \n",
       "3                      NaN                 NaN  \n",
       "4                      NaN                 NaN  \n",
       "...                    ...                 ...  \n",
       "278909                 NaN                 NaN  \n",
       "278910                 NaN                 NaN  \n",
       "278911                 NaN                 NaN  \n",
       "278912                 NaN                 NaN  \n",
       "278913                 NaN                 NaN  \n",
       "\n",
       "[278914 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "languageTags[\"Germanic\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English\n",
      "recevied\n",
      "german\n",
      "swed\n",
      "nor\n",
      "167068\n"
     ]
    }
   ],
   "source": [
    "temparr = []\n",
    "for dataset in languageTags[\"Germanic\"]:\n",
    "    sampleSetPopulation = len(dataset)//3\n",
    "    print(dataset.name)\n",
    "    for i in range(sampleSetPopulation):\n",
    "#         print(i)\n",
    "        temp = []\n",
    "        binaryV = convertDictionaryToVector(processWord(dataset['Word'][i], \"Germanic\"))\n",
    "        for j in binaryV:\n",
    "            temp.append(int(j))\n",
    "        for k in languageFamily[\"Germanic\"]:\n",
    "            temp.append(int(k))\n",
    "        temparr.append(temp)\n",
    "\n",
    "print(len(temparr))\n",
    "bigdataset = pd.DataFrame(temparr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1294</th>\n",
       "      <th>1295</th>\n",
       "      <th>1296</th>\n",
       "      <th>1297</th>\n",
       "      <th>1298</th>\n",
       "      <th>1299</th>\n",
       "      <th>1300</th>\n",
       "      <th>1301</th>\n",
       "      <th>1302</th>\n",
       "      <th>1303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167063</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167064</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167065</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167066</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167067</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167068 rows × 1304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2     3     4     5     6     7     8     9     ...  1294  \\\n",
       "0          0     0     1     0     0     0     0     0     0     0  ...     0   \n",
       "1          0     0     0     0     0     1     0     0     0     0  ...     0   \n",
       "2          0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "3          0     0     0     0     0     0     1     0     0     0  ...     0   \n",
       "4          0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
       "167063     0     0     0     0     0     0     1     0     0     0  ...     0   \n",
       "167064     0     0     0     0     0     0     1     0     0     0  ...     0   \n",
       "167065     0     0     0     0     0     0     0     1     0     0  ...     0   \n",
       "167066     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "167067     0     0     0     0     0     0     0     0     0     0  ...     0   \n",
       "\n",
       "        1295  1296  1297  1298  1299  1300  1301  1302  1303  \n",
       "0          0     0     0     0     0     1     0     0     0  \n",
       "1          0     0     0     0     0     1     0     0     0  \n",
       "2          0     0     0     0     0     1     0     0     0  \n",
       "3          0     0     0     0     0     1     0     0     0  \n",
       "4          0     0     0     0     0     1     0     0     0  \n",
       "...      ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "167063     0     0     0     0     0     1     0     0     0  \n",
       "167064     0     0     0     0     0     1     0     0     0  \n",
       "167065     0     0     0     0     0     1     0     0     0  \n",
       "167066     0     0     0     0     0     1     0     0     0  \n",
       "167067     0     0     0     0     0     1     0     0     0  \n",
       "\n",
       "[167068 rows x 1304 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigdataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quebec\n",
      "mexico\n",
      "280614\n"
     ]
    }
   ],
   "source": [
    "temparr2 = []\n",
    "for dataset in languageTags[\"Romance\"]:\n",
    "    sampleSetPopulation = len(dataset)//3\n",
    "    print(dataset.name)\n",
    "    for i in range(sampleSetPopulation):\n",
    "#         print(i)\n",
    "        temp = []\n",
    "        binaryV = convertDictionaryToVector(processWord(dataset['Word'][i], \"Romance\"))\n",
    "        for j in binaryV:\n",
    "            temp.append(int(j))\n",
    "        for k in languageFamily[\"Romance\"]:\n",
    "            temp.append(int(k))\n",
    "        temparr2.append(temp)\n",
    "\n",
    "print(len(temparr2))\n",
    "bigdataset2 = pd.DataFrame(temparr2)\n",
    "\n",
    "########SPANISH##########\n",
    "# temparr5 = []\n",
    "# for i in range(len(df8['binaryVector'])):\n",
    "#     temp = []\n",
    "#     for j in df8['binaryVector'][i]:\n",
    "#         temp.append(int(j))\n",
    "#     for k in df8['languageFamily'][i]:\n",
    "#         temp.append(int(k))\n",
    "#     temparr5.append(temp)\n",
    "\n",
    "# samplePopulation5 = shuffle(temparr5)\n",
    "# bigdataset2 = pd.DataFrame(temparr5[:len(temparr5)//3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #######FRENCH###########\n",
    "# temparr2 = []\n",
    "# for i in range(len(df7['binaryVector'])):\n",
    "#     temp = []\n",
    "#     for j in processWord df7['Word'][i]:\n",
    "#         temp.append(int(j))\n",
    "#     for k in df7['languageFamily'][i]:\n",
    "#         temp.append(int(k))\n",
    "#     temparr2.append(temp)\n",
    "\n",
    "# samplePopulation2 = shuffle(temparr2)\n",
    "# bigdataset3 = pd.DataFrame(temparr2[:len(temparr2)//3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926\n",
      "mandarin\n",
      "0\n",
      "Orginal is: 行事\n",
      "translated word is: act\n",
      "1\n",
      "Orginal is: 特技\n",
      "translated word is: trick\n",
      "2\n",
      "Orginal is: 驴驹\n",
      "translated word is: foal\n",
      "3\n",
      "Orginal is: 放鞭炮\n",
      "translated word is: firecracker\n",
      "4\n",
      "Orginal is: 栨\n",
      "translated word is: bamboo\n",
      "5\n",
      "Orginal is: 前门\n",
      "translated word is: frontdoor\n",
      "6\n",
      "Orginal is: 稗史\n",
      "translated word is: bookofanecdotes\n",
      "7\n",
      "Orginal is: 洋裙\n",
      "translated word is: skirt\n",
      "8\n",
      "Orginal is: 拱手\n",
      "translated word is: gong\n",
      "9\n",
      "Orginal is: 檐沟\n",
      "translated word is: pitch\n",
      "10\n",
      "Orginal is: 梈\n",
      "translated word is: bamboo\n",
      "11\n",
      "Orginal is: 干瘦\n",
      "translated word is: skinny\n",
      "12\n",
      "Orginal is: 心弦\n",
      "translated word is: heartstring\n",
      "13\n",
      "Orginal is: 㼮\n",
      "translated word is: bamboo\n",
      "14\n",
      "Orginal is: 自背黑锅\n",
      "translated word is: backbone\n",
      "15\n",
      "Orginal is: 违约\n",
      "translated word is: default\n",
      "16\n",
      "Orginal is: 婆婆\n",
      "translated word is: motherinlaw\n",
      "17\n",
      "Orginal is: 拉扯\n",
      "translated word is: pull\n",
      "18\n",
      "Orginal is: 辞世\n",
      "translated word is: resign\n",
      "19\n",
      "Orginal is: 复印\n",
      "translated word is: copy\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# # translator.raise_Exception = True\n",
    "# temparr3 = []\n",
    "# for dataset in languageTags[\"Sino-Tebetan\"]:\n",
    "#     sampleSetPopulation = len(dataset)//3\n",
    "#     print(sampleSetPopulation)\n",
    "#     print(dataset.name)\n",
    "#     for i in range(20):\n",
    "#         print(i)\n",
    "#         temp = []\n",
    "#         binaryV = convertDictionaryToVector(processWord(dataset['Word'][i], \"Sino-Tebetan\"))\n",
    "#         for j in binaryV:\n",
    "#             temp.append(int(j))\n",
    "#         for k in languageFamily[\"Sino-Tebetan\"]:\n",
    "#             temp.append(int(k))\n",
    "#         temparr3.append(temp)\n",
    "\n",
    "# print(len(temparr3))\n",
    "# bigdataset3 = pd.DataFrame(temparr3)\n",
    "\n",
    "# # ##################\n",
    "# # samplePopulation3 = shuffle(temparr3)\n",
    "# # bigdataset4 = pd.DataFrame(temparr3[:len(temparr3)//3])\n",
    "# # .sample(frac=1)\n",
    "\n",
    "# # temparr3 = []\n",
    "# # for  i in range(1304):\n",
    "# #     temp = []\n",
    "# #     binaryV = convertDictionaryToVector(procesWord(dataset['Word'][i], \"Sino-Tebetan\"))\n",
    "# #     for j in binaryV:\n",
    "# #         temp.append(int(j))\n",
    "# #     for k in dataset['languageFamily'][i]:\n",
    "# #             temp.append(int(k))\n",
    "# #     temparr3.append(temp)\n",
    "\n",
    "# # samplePopulation3 = shuffle(temparr3)\n",
    "# # bigdataset4 = pd.DataFrame(temparr3[:len(temparr3)//3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# temparr4 = []\n",
    "# for dataset in languageTags[\"Japonic\"]:\n",
    "#     sampleSetPopulation = len(dataset)//3\n",
    "#     print(dataset.name)\n",
    "#     for i in range(sampleSetPopulation):\n",
    "# #         print(i)\n",
    "#         temp = []\n",
    "#         binaryV = convertDictionaryToVector(processWord(dataset['Word'][i], \"Japonic\"))\n",
    "#         for j in binaryV:\n",
    "#             temp.append(int(j))\n",
    "#         for k in languageFamily[\"Japonic\"]:\n",
    "#             temp.append(int(k))\n",
    "#         temparr4.append(temp)\n",
    "\n",
    "# print(len(temparr))\n",
    "# bigdataset4 = pd.DataFrame(temparr4)\n",
    "\n",
    "# ##################\n",
    "# # temparr4 = []\n",
    "# # for dataset in languageTags[\"Japonic\"]:\n",
    "# #     for  i in range(len(dataset['binaryVector'])):\n",
    "# #         temp = []\n",
    "# #         binaryV = convertDictionaryToVector(procesWord(dataset['Word'][i], \"Japonic\"))\n",
    "# #         for j in binaryV:\n",
    "# #             temp.append(int(j))\n",
    "# #         for k in dataset['languageFamily'][i]:\n",
    "# #             temp.append(int(k))\n",
    "# #         temparr4.append(temp)\n",
    "\n",
    "# # samplePopulation4 = shuffle(temparr4)\n",
    "# # bigdataset5 = pd.DataFrame(temparr4[:len(temparr4)//3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffledDatasets = [bigdataset, bigdataset2, bigdataset3, bigdataset4]\n",
    "# concatenatedDatasets = pd.concat(shuffledDatasets)\n",
    "shuffledDatasets = [bigdataset, bigdataset2]\n",
    "concatenatedDatasets = pd.concat(shuffledDatasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %store concatenatedDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalDataset = concatenatedDatasets.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Sequential()\n",
    "network.add(Dense(150, activation='relu'))\n",
    "network.add(Dense(100, activation='relu'))\n",
    "network.add(Dense(100, activation='relu'))\n",
    "network.add(Dense(2, activation='sigmoid'))\n",
    "network.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# # print(len(resultXTrain))\n",
    "# # print(len(resultYTrain))\n",
    "# # print(len(resultXTest))\n",
    "# # print(len(resultYTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetLength = len(concatenatedDatasets)\n",
    "index = round(datasetLength * .05)\n",
    "print(index)\n",
    "\n",
    "\n",
    "N = 4\n",
    "# Select last 4 columns of dataframe\n",
    "xValues = concatenatedDatasets.iloc[:, 0:-N]\n",
    "yValues = concatenatedDatasets.iloc[: , -N:]\n",
    "resultXTrain = xValues[:index]\n",
    "resultXTest = xValues[index:]\n",
    "resultYTrain = yValues[:index]\n",
    "resultYTest = yValues[index:]\n",
    "print(\"X Values :\")\n",
    "print(xValues)\n",
    "print(\"Y Values :\")\n",
    "print(yValues)\n",
    "\n",
    "# %store resultXTrain\n",
    "# %store resultYTrain\n",
    "# %store resultXTest\n",
    "# %store resultYTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in finalDataset[0][0]:\n",
    "#     print(type(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultXTrain\n",
    "# print(resultXTrain)\n",
    "# print(type(resultXTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# finalDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resultYTrain\n",
    "# print(resultYTrain)\n",
    "# print(type(resultYTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network.fit(resultXTrain, resultYTrain, epochs=80, validation_data=(resultXTest, resultYTest), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN = Sequential()\n",
    "# NN.add(Dense(150, activation='relu'))\n",
    "# NN.add(Dense(100, activation='relu'))\n",
    "# NN.add(Dense(100, activation='relu'))\n",
    "# NN.add(Dense(len(languageTags), activation='sigmoid'))\n",
    "# NN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# NN.fit(resultXTrain, resultYTrain, epochs=85, validation_data=(resultXTest, resultYTest), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = [\"colonel\", \"Garçon\", \"對唔住\", \"おねがいします\"]\n",
    "# processedWords = [processWord(words[0], \"Germanic\"),\n",
    "#                  processWord(words[1], \"Romance\"),\n",
    "#                  processWord(words[2], \"Sino-Tebetan\"),\n",
    "#                  processWord(words[3], \"Japonic\")]\n",
    "# print(\"\\n\\n\\n\\n\\n\")\n",
    "# # for v in processedWords:\n",
    "# #     print(v)\n",
    "\n",
    "# # print(translator.translate(words[2], dest='en', src='zh-cn').text.lower())\n",
    "# # print(translator.translate(\"おねがいします\", dest='en',src='ja').text.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "00aa7deaa002eace83cde9fdbccd45f22b0b2c9563d542b6baf8a183e1387b2a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit (conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
